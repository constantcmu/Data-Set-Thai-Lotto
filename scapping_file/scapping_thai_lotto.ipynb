{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including requests, BeautifulSoup, pandas, os, and concurrent.futures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import os\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Classes\n",
    "Define the ArchivePage data class to store the list of URLs and the next page URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ArchivePage:\n",
    "    archiveList: List[str]\n",
    "    nextPageUrl: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Helper Functions\n",
    "Define the helper functions used for scraping data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArchivePage(url):\n",
    "    print(f\"Page = {url}\")\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        nextPageUrl = \"\"\n",
    "        lotto = []\n",
    "        for link in soup.find_all('a', class_='pagination__item--next'):\n",
    "            nextPageUrl = link.get('href')\n",
    "            break\n",
    "\n",
    "        divContent = soup.find(\n",
    "            'div', class_=['box-cell', 'box-cell--lotto', 'content'])\n",
    "\n",
    "        for link in divContent.find_all('a'):\n",
    "            lottoUrl = link.get('href')\n",
    "            if \"/lotto/check/\" in lottoUrl:\n",
    "                lotto.append(lottoUrl)\n",
    "\n",
    "        return ArchivePage(archiveList=lotto, nextPageUrl=nextPageUrl)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "def getDate(url):\n",
    "    d = url.split(\"/\")\n",
    "    while (\"\" in d):\n",
    "        d.remove(\"\")\n",
    "    dateStr = d[len(d)-1]\n",
    "    date = dateStr[0:2]\n",
    "    month = dateStr[2:4]\n",
    "    year = str(int(dateStr[4:8])-543)\n",
    "    return f\"{year}-{month}-{date}\"\n",
    "\n",
    "def scappingLotto(url, prize_type):\n",
    "    if url == 'https://news.sanook.com/lotto/check/ผลสลากกินแบ่งรัฐบาลงวดประจำวันที่1สิงหาคม2552/':\n",
    "        url = 'https://news.sanook.com/lotto/check/01082552/'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    date = getDate(url)\n",
    "    print(f'{date} = {url}')\n",
    "\n",
    "    row = {\n",
    "        'date': date,\n",
    "        prize_type: []\n",
    "    }\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        if prize_type == 'prize_1st':\n",
    "            columns = soup.find_all('div', class_='lottocheck__column')\n",
    "            if columns:\n",
    "                for col in columns:\n",
    "                    for num in col.find_all('strong'):\n",
    "                        if len(row[prize_type]) == 0:  # Only append if list is empty\n",
    "                            row[prize_type].append(num.text)\n",
    "        elif prize_type == 'nearby_1st':\n",
    "            div = soup.find('div', class_='lottocheck__sec--nearby')\n",
    "            if div:\n",
    "                for ele in div.find_all('strong', class_=\"lotto__number\"):\n",
    "                    row[prize_type].append(ele.text)\n",
    "        elif prize_type in ['prize_2nd', 'prize_3rd', 'prize_4th', 'prize_5th']:\n",
    "            sections = soup.find_all('div', class_='lottocheck__sec')\n",
    "            if sections:\n",
    "                for section in sections:\n",
    "                    divs = section.find_all('div', class_='lottocheck__box-item')\n",
    "                    nums = []\n",
    "                    for div in divs:\n",
    "                        for span in div.find_all('span', class_='lotto__number'):\n",
    "                            nums.append(span.text)\n",
    "                    row[prize_type] = nums\n",
    "        elif prize_type == 'prize_2digits':\n",
    "            columns = soup.find_all('div', class_='lottocheck__column')\n",
    "            if columns:\n",
    "                for col in columns:\n",
    "                    for num in col.find_all('strong'):\n",
    "                        if \"เลขท้าย 2 ตัว\" in col.text:\n",
    "                            row[prize_type].append(num.text)\n",
    "        elif prize_type in ['prize_pre_3digit', 'prize_sub_3digits']:\n",
    "            columns = soup.find_all('div', class_='lottocheck__column')\n",
    "            if columns:\n",
    "                for col in columns:\n",
    "                    for num in col.find_all('strong'):\n",
    "                        if \"เลขหน้า\" in col.text:\n",
    "                            row['prize_pre_3digit'].append(num.text)\n",
    "                        elif \"เลขท้าย\" in col.text:\n",
    "                            row['prize_sub_3digits'].append(num.text)\n",
    "            \n",
    "            # Adjust prize_pre_3digit and prize_sub_3digits if necessary\n",
    "            if len(row['prize_pre_3digit']) < 2 and len(row['prize_sub_3digits']) > 2:\n",
    "                row['prize_pre_3digit'] = row['prize_sub_3digits'][:2]\n",
    "                row['prize_sub_3digits'] = row['prize_sub_3digits'][2:]\n",
    "\n",
    "            # Ensure both lists have exactly 2 elements\n",
    "            row['prize_pre_3digit'].extend([''] * (2 - len(row['prize_pre_3digit'])))\n",
    "            row['prize_sub_3digits'].extend([''] * (2 - len(row['prize_sub_3digits'])))\n",
    "\n",
    "        return row\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getArchivePage Function\n",
    "Define the getArchivePage function to retrieve the archive page and extract URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArchivePage(url):\n",
    "    print(f\"Page = {url}\")\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        nextPageUrl = \"\"\n",
    "        lotto = []\n",
    "        for link in soup.find_all('a', class_='pagination__item--next'):\n",
    "            nextPageUrl = link.get('href')\n",
    "            break\n",
    "\n",
    "        divContent = soup.find(\n",
    "            'div', class_=['box-cell', 'box-cell--lotto', 'content'])\n",
    "\n",
    "        for link in divContent.find_all('a'):\n",
    "            lottoUrl = link.get('href')\n",
    "            if \"/lotto/check/\" in lottoUrl:\n",
    "                lotto.append(lottoUrl)\n",
    "\n",
    "        return ArchivePage(archiveList=lotto, nextPageUrl=nextPageUrl)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getDate Function\n",
    "Define the getDate function to extract and format the date from the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDate(url):\n",
    "    # Split the URL by \"/\" and remove empty strings\n",
    "    d = url.split(\"/\")\n",
    "    while (\"\" in d):\n",
    "        d.remove(\"\")\n",
    "    \n",
    "    # Extract the date string from the URL\n",
    "    dateStr = d[len(d)-1]\n",
    "    \n",
    "    # Extract day, month, and year from the date string\n",
    "    date = dateStr[0:2]\n",
    "    month = dateStr[2:4]\n",
    "    year = str(int(dateStr[4:8])-543)  # Convert Buddhist year to Gregorian year\n",
    "    \n",
    "    # Return the formatted date string\n",
    "    return f\"{year}-{month}-{date}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scappingLotto Functions\n",
    "Define the scappingLotto functions for each prize category (1st, Nearby 1st, 2nd, 3rd, 4th, 5th, 3-Digit, 2-Digit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scappingLotto(url, prize_type):\n",
    "    if url == 'https://news.sanook.com/lotto/check/ผลสลากกินแบ่งรัฐบาลงวดประจำวันที่1สิงหาคม2552/':\n",
    "        url = 'https://news.sanook.com/lotto/check/01082552/'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    date = getDate(url)\n",
    "    print(f'{date} = {url}')\n",
    "\n",
    "    row = {\n",
    "        'date': date,\n",
    "        prize_type: []\n",
    "    }\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        if prize_type == 'prize_1st':\n",
    "            columns = soup.find_all('div', class_='lottocheck__column')\n",
    "            if columns:\n",
    "                for col in columns:\n",
    "                    for num in col.find_all('strong'):\n",
    "                        if len(row[prize_type]) == 0:  # Only append if list is empty\n",
    "                            row[prize_type].append(num.text)\n",
    "        elif prize_type == 'nearby_1st':\n",
    "            div = soup.find('div', class_='lottocheck__sec--nearby')\n",
    "            if div:\n",
    "                for ele in div.find_all('strong', class_=\"lotto__number\"):\n",
    "                    row[prize_type].append(ele.text)\n",
    "        elif prize_type in ['prize_2nd', 'prize_3rd', 'prize_4th', 'prize_5th']:\n",
    "            sections = soup.find_all('div', class_='lottocheck__sec')\n",
    "            if sections:\n",
    "                for section in sections:\n",
    "                    divs = section.find_all('div', class_='lottocheck__box-item')\n",
    "                    nums = []\n",
    "                    for div in divs:\n",
    "                        for span in div.find_all('span', class_='lotto__number'):\n",
    "                            nums.append(span.text)\n",
    "                    row[prize_type] = nums\n",
    "        elif prize_type == 'prize_2digits':\n",
    "            columns = soup.find_all('div', class_='lottocheck__column')\n",
    "            if columns:\n",
    "                for col in columns:\n",
    "                    for num in col.find_all('strong'):\n",
    "                        if \"เลขท้าย 2 ตัว\" in col.text:\n",
    "                            row[prize_type].append(num.text)\n",
    "        elif prize_type in ['prize_pre_3digit', 'prize_sub_3digits']:\n",
    "            columns = soup.find_all('div', class_='lottocheck__column')\n",
    "            if columns:\n",
    "                for col in columns:\n",
    "                    for num in col.find_all('strong'):\n",
    "                        if \"เลขหน้า\" in col.text:\n",
    "                            row['prize_pre_3digit'].append(num.text)\n",
    "                        elif \"เลขท้าย\" in col.text:\n",
    "                            row['prize_sub_3digits'].append(num.text)\n",
    "            \n",
    "            # Adjust prize_pre_3digit and prize_sub_3digits if necessary\n",
    "            if len(row['prize_pre_3digit']) < 2 and len(row['prize_sub_3digits']) > 2:\n",
    "                row['prize_pre_3digit'] = row['prize_sub_3digits'][:2]\n",
    "                row['prize_sub_3digits'] = row['prize_sub_3digits'][2:]\n",
    "\n",
    "            # Ensure both lists have exactly 2 elements\n",
    "            row['prize_pre_3digit'].extend([''] * (2 - len(row['prize_pre_3digit'])))\n",
    "            row['prize_sub_3digits'].extend([''] * (2 - len(row['prize_sub_3digits'])))\n",
    "\n",
    "        return row\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize DataFrames and Variables\n",
    "Initialize the DataFrames and variables needed for storing the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrames and Variables\n",
    "\n",
    "# Define the columns for each DataFrame\n",
    "columns_1st = ['date', 'prize_1st']\n",
    "columns_nearby_1st = ['date', 'nearby_1st']\n",
    "columns_2nd = ['date', 'prize_2nd']\n",
    "columns_3rd = ['date', 'prize_3rd']\n",
    "columns_4th = ['date', 'prize_4th']\n",
    "columns_5th = ['date', 'prize_5th']\n",
    "columns_2digit = ['date', 'prize_2digits']\n",
    "columns_3digit = ['date', 'prize_pre_3digit', 'prize_sub_3digits']\n",
    "\n",
    "# Initialize DataFrames for each prize type\n",
    "df_1st = pd.DataFrame(columns=columns_1st)\n",
    "df_nearby_1st = pd.DataFrame(columns=columns_nearby_1st)\n",
    "df_2nd = pd.DataFrame(columns=columns_2nd)\n",
    "df_3rd = pd.DataFrame(columns=columns_3rd)\n",
    "df_4th = pd.DataFrame(columns=columns_4th)\n",
    "df_5th = pd.DataFrame(columns=columns_5th)\n",
    "df_2digit = pd.DataFrame(columns=columns_2digit)\n",
    "df_3digit = pd.DataFrame(columns=columns_3digit)\n",
    "\n",
    "# Initialize archive URL and header flag\n",
    "archive_url = \"https://news.sanook.com/lotto/archive/\"\n",
    "header = True\n",
    "\n",
    "# Remove existing CSV and Parquet files if they exist\n",
    "file_paths = [\n",
    "    'prize_1th.csv', 'lotto_prize_1th.parquet',\n",
    "    'nearby_1st.csv', 'lotto_nearby_1st.parquet',\n",
    "    'prize_2nd.csv', 'lotto_prize_2nd.parquet',\n",
    "    'prize_3rd.csv', 'prize_3rd.parquet',\n",
    "    'prize_4th.csv', 'prize_4th.parquet',\n",
    "    'prize_5th.csv', 'prize_5th.parquet',\n",
    "    'prize_2digit.csv', 'prize_2digit.parquet',\n",
    "    'prize_3digit.csv', 'prize_3digit.parquet'\n",
    "]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Loop for Scraping Data\n",
    "Define the main loop that iterates through the archive pages and scrapes data for each prize category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page = https://news.sanook.com/lotto/archive/\n",
      "2025-02-16 = https://news.sanook.com/lotto/check/16022568/\n",
      "2025-02-01 = https://news.sanook.com/lotto/check/01022568/\n",
      "2025-01-02 = https://news.sanook.com/lotto/check/02012568/\n",
      "2025-01-17 = https://news.sanook.com/lotto/check/17012568/\n",
      "2024-12-01 = https://news.sanook.com/lotto/check/01122567/\n",
      "2024-12-16 = https://news.sanook.com/lotto/check/16122567/\n",
      "2024-11-16 = https://news.sanook.com/lotto/check/16112567/\n",
      "2024-11-01 = https://news.sanook.com/lotto/check/01112567/\n",
      "2024-10-16 = https://news.sanook.com/lotto/check/16102567/\n",
      "2024-10-01 = https://news.sanook.com/lotto/check/01102567/\n",
      "2024-09-16 = https://news.sanook.com/lotto/check/16092567/\n",
      "2024-09-01 = https://news.sanook.com/lotto/check/01092567/\n",
      "2024-08-01 = https://news.sanook.com/lotto/check/01082567/\n",
      "2024-07-16 = https://news.sanook.com/lotto/check/16072567/\n",
      "2024-07-01 = https://news.sanook.com/lotto/check/01072567/\n",
      "2024-08-16 = https://news.sanook.com/lotto/check/16082567/\n",
      "2024-06-16 = https://news.sanook.com/lotto/check/16062567/\n",
      "2024-06-01 = https://news.sanook.com/lotto/check/01062567/\n",
      "2024-05-16 = https://news.sanook.com/lotto/check/16052567/\n",
      "2024-05-02 = https://news.sanook.com/lotto/check/02052567/\n",
      "2024-04-16 = https://news.sanook.com/lotto/check/16042567/\n",
      "2024-12-16 = https://news.sanook.com/lotto/check/16122567/2025-02-01 = https://news.sanook.com/lotto/check/01022568/\n",
      "\n",
      "2024-11-01 = https://news.sanook.com/lotto/check/01112567/\n",
      "2025-01-17 = https://news.sanook.com/lotto/check/17012568/\n",
      "2025-01-02 = https://news.sanook.com/lotto/check/02012568/\n",
      "2025-02-16 = https://news.sanook.com/lotto/check/16022568/\n",
      "2024-11-16 = https://news.sanook.com/lotto/check/16112567/\n",
      "2024-12-01 = https://news.sanook.com/lotto/check/01122567/\n",
      "2024-09-16 = https://news.sanook.com/lotto/check/16092567/\n",
      "2024-10-01 = https://news.sanook.com/lotto/check/01102567/\n",
      "2024-09-01 = https://news.sanook.com/lotto/check/01092567/\n",
      "2024-08-01 = https://news.sanook.com/lotto/check/01082567/\n",
      "2024-10-16 = https://news.sanook.com/lotto/check/16102567/\n",
      "2024-07-01 = https://news.sanook.com/lotto/check/01072567/\n",
      "2024-07-16 = https://news.sanook.com/lotto/check/16072567/\n",
      "2024-06-16 = https://news.sanook.com/lotto/check/16062567/\n",
      "2024-06-01 = https://news.sanook.com/lotto/check/01062567/\n",
      "2024-08-16 = https://news.sanook.com/lotto/check/16082567/\n",
      "2024-05-16 = https://news.sanook.com/lotto/check/16052567/\n",
      "2024-04-16 = https://news.sanook.com/lotto/check/16042567/\n",
      "2024-05-02 = https://news.sanook.com/lotto/check/02052567/\n",
      "2024-12-16 = https://news.sanook.com/lotto/check/16122567/\n",
      "2025-02-16 = https://news.sanook.com/lotto/check/16022568/\n",
      "2025-01-17 = https://news.sanook.com/lotto/check/17012568/\n",
      "2025-01-02 = https://news.sanook.com/lotto/check/02012568/\n",
      "2025-02-01 = https://news.sanook.com/lotto/check/01022568/\n",
      "2024-11-16 = https://news.sanook.com/lotto/check/16112567/\n",
      "2024-11-01 = https://news.sanook.com/lotto/check/01112567/\n",
      "2024-12-01 = https://news.sanook.com/lotto/check/01122567/\n",
      "2024-10-16 = https://news.sanook.com/lotto/check/16102567/\n",
      "2024-09-01 = https://news.sanook.com/lotto/check/01092567/\n",
      "2024-08-01 = https://news.sanook.com/lotto/check/01082567/\n",
      "2024-07-16 = https://news.sanook.com/lotto/check/16072567/\n",
      "2024-07-01 = https://news.sanook.com/lotto/check/01072567/\n",
      "2024-09-16 = https://news.sanook.com/lotto/check/16092567/\n",
      "2024-10-01 = https://news.sanook.com/lotto/check/01102567/\n",
      "2024-08-16 = https://news.sanook.com/lotto/check/16082567/\n",
      "2024-06-16 = https://news.sanook.com/lotto/check/16062567/\n",
      "2024-06-01 = https://news.sanook.com/lotto/check/01062567/\n",
      "2024-05-16 = https://news.sanook.com/lotto/check/16052567/\n",
      "2024-05-02 = https://news.sanook.com/lotto/check/02052567/\n",
      "2024-04-16 = https://news.sanook.com/lotto/check/16042567/\n",
      "2024-11-01 = https://news.sanook.com/lotto/check/01112567/\n",
      "2025-02-16 = https://news.sanook.com/lotto/check/16022568/\n",
      "2025-01-02 = https://news.sanook.com/lotto/check/02012568/\n",
      "2024-12-16 = https://news.sanook.com/lotto/check/16122567/\n",
      "2024-11-16 = https://news.sanook.com/lotto/check/16112567/\n",
      "2025-02-01 = https://news.sanook.com/lotto/check/01022568/\n",
      "2025-01-17 = https://news.sanook.com/lotto/check/17012568/\n",
      "2024-12-01 = https://news.sanook.com/lotto/check/01122567/\n",
      "2024-10-01 = https://news.sanook.com/lotto/check/01102567/\n",
      "2024-10-16 = https://news.sanook.com/lotto/check/16102567/\n",
      "2024-09-16 = https://news.sanook.com/lotto/check/16092567/\n",
      "2024-09-01 = https://news.sanook.com/lotto/check/01092567/\n",
      "2024-08-01 = https://news.sanook.com/lotto/check/01082567/\n",
      "2024-08-16 = https://news.sanook.com/lotto/check/16082567/\n",
      "2024-07-16 = https://news.sanook.com/lotto/check/16072567/\n",
      "2024-06-01 = https://news.sanook.com/lotto/check/01062567/\n",
      "2024-07-01 = https://news.sanook.com/lotto/check/01072567/\n",
      "2024-05-02 = https://news.sanook.com/lotto/check/02052567/\n",
      "2024-06-16 = https://news.sanook.com/lotto/check/16062567/\n",
      "2024-05-16 = https://news.sanook.com/lotto/check/16052567/\n",
      "2024-04-16 = https://news.sanook.com/lotto/check/16042567/\n",
      "2024-11-01 = https://news.sanook.com/lotto/check/01112567/\n",
      "2025-02-16 = https://news.sanook.com/lotto/check/16022568/\n",
      "2024-12-16 = https://news.sanook.com/lotto/check/16122567/\n",
      "2024-11-16 = https://news.sanook.com/lotto/check/16112567/\n",
      "2025-01-17 = https://news.sanook.com/lotto/check/17012568/\n",
      "2024-12-01 = https://news.sanook.com/lotto/check/01122567/\n",
      "2025-02-01 = https://news.sanook.com/lotto/check/01022568/2025-01-02 = https://news.sanook.com/lotto/check/02012568/\n",
      "\n",
      "2024-10-16 = https://news.sanook.com/lotto/check/16102567/\n",
      "2024-09-16 = https://news.sanook.com/lotto/check/16092567/\n",
      "2024-09-01 = https://news.sanook.com/lotto/check/01092567/2024-08-16 = https://news.sanook.com/lotto/check/16082567/\n",
      "\n",
      "2024-10-01 = https://news.sanook.com/lotto/check/01102567/\n",
      "2024-07-16 = https://news.sanook.com/lotto/check/16072567/\n",
      "2024-07-01 = https://news.sanook.com/lotto/check/01072567/\n",
      "2024-08-01 = https://news.sanook.com/lotto/check/01082567/\n",
      "2024-06-16 = https://news.sanook.com/lotto/check/16062567/\n",
      "2024-06-01 = https://news.sanook.com/lotto/check/01062567/\n",
      "2024-05-16 = https://news.sanook.com/lotto/check/16052567/\n",
      "2024-05-02 = https://news.sanook.com/lotto/check/02052567/\n",
      "2024-04-16 = https://news.sanook.com/lotto/check/16042567/\n",
      "2025-02-16 = https://news.sanook.com/lotto/check/16022568/\n",
      "2024-11-16 = https://news.sanook.com/lotto/check/16112567/\n",
      "2025-01-02 = https://news.sanook.com/lotto/check/02012568/\n",
      "2025-01-17 = https://news.sanook.com/lotto/check/17012568/2024-12-16 = https://news.sanook.com/lotto/check/16122567/\n",
      "2025-02-01 = https://news.sanook.com/lotto/check/01022568/\n",
      "\n",
      "2024-11-01 = https://news.sanook.com/lotto/check/01112567/\n",
      "2024-12-01 = https://news.sanook.com/lotto/check/01122567/\n",
      "2024-09-16 = https://news.sanook.com/lotto/check/16092567/\n",
      "2024-09-01 = https://news.sanook.com/lotto/check/01092567/\n",
      "2024-08-01 = https://news.sanook.com/lotto/check/01082567/\n",
      "2024-08-16 = https://news.sanook.com/lotto/check/16082567/\n",
      "2024-10-01 = https://news.sanook.com/lotto/check/01102567/\n",
      "2024-07-16 = https://news.sanook.com/lotto/check/16072567/\n",
      "2024-07-01 = https://news.sanook.com/lotto/check/01072567/\n",
      "2024-10-16 = https://news.sanook.com/lotto/check/16102567/\n",
      "2024-06-16 = https://news.sanook.com/lotto/check/16062567/\n",
      "2024-06-01 = https://news.sanook.com/lotto/check/01062567/\n",
      "2024-05-16 = https://news.sanook.com/lotto/check/16052567/\n",
      "2024-04-16 = https://news.sanook.com/lotto/check/16042567/\n",
      "2024-05-02 = https://news.sanook.com/lotto/check/02052567/\n",
      "2025-02-16 = https://news.sanook.com/lotto/check/16022568/\n",
      "2024-12-01 = https://news.sanook.com/lotto/check/01122567/\n",
      "2025-01-17 = https://news.sanook.com/lotto/check/17012568/2025-01-02 = https://news.sanook.com/lotto/check/02012568/\n",
      "\n",
      "2025-02-01 = https://news.sanook.com/lotto/check/01022568/\n",
      "2024-12-16 = https://news.sanook.com/lotto/check/16122567/\n",
      "2024-11-01 = https://news.sanook.com/lotto/check/01112567/\n",
      "2024-11-16 = https://news.sanook.com/lotto/check/16112567/\n",
      "2024-10-16 = https://news.sanook.com/lotto/check/16102567/\n",
      "2024-09-16 = https://news.sanook.com/lotto/check/16092567/\n",
      "2024-10-01 = https://news.sanook.com/lotto/check/01102567/\n",
      "2024-08-01 = https://news.sanook.com/lotto/check/01082567/\n",
      "2024-08-16 = https://news.sanook.com/lotto/check/16082567/\n",
      "2024-07-16 = https://news.sanook.com/lotto/check/16072567/\n",
      "2024-07-01 = https://news.sanook.com/lotto/check/01072567/\n",
      "2024-09-01 = https://news.sanook.com/lotto/check/01092567/\n",
      "2024-06-16 = https://news.sanook.com/lotto/check/16062567/\n",
      "2024-06-01 = https://news.sanook.com/lotto/check/01062567/\n",
      "2024-05-16 = https://news.sanook.com/lotto/check/16052567/\n",
      "2024-05-02 = https://news.sanook.com/lotto/check/02052567/\n",
      "2024-04-16 = https://news.sanook.com/lotto/check/16042567/\n",
      "2025-02-01 = https://news.sanook.com/lotto/check/01022568/\n",
      "2025-02-16 = https://news.sanook.com/lotto/check/16022568/\n",
      "2025-01-02 = https://news.sanook.com/lotto/check/02012568/\n",
      "2025-01-17 = https://news.sanook.com/lotto/check/17012568/\n",
      "2024-11-01 = https://news.sanook.com/lotto/check/01112567/\n",
      "2024-12-01 = https://news.sanook.com/lotto/check/01122567/\n",
      "2024-12-16 = https://news.sanook.com/lotto/check/16122567/\n",
      "2024-11-16 = https://news.sanook.com/lotto/check/16112567/\n",
      "2024-09-16 = https://news.sanook.com/lotto/check/16092567/\n",
      "2024-09-01 = https://news.sanook.com/lotto/check/01092567/\n",
      "2024-10-16 = https://news.sanook.com/lotto/check/16102567/\n",
      "2024-08-01 = https://news.sanook.com/lotto/check/01082567/\n",
      "2024-08-16 = https://news.sanook.com/lotto/check/16082567/\n",
      "2024-10-01 = https://news.sanook.com/lotto/check/01102567/\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'prize_sub_3digits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     results_5th \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m url: scappingLotto(url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprize_5th\u001b[39m\u001b[38;5;124m'\u001b[39m), archive\u001b[38;5;241m.\u001b[39marchiveList))\n\u001b[0;32m     14\u001b[0m     results_2digit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m url: scappingLotto(url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprize_2digits\u001b[39m\u001b[38;5;124m'\u001b[39m), archive\u001b[38;5;241m.\u001b[39marchiveList))\n\u001b[1;32m---> 15\u001b[0m     results_3digit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscappingLotto\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprize_pre_3digit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marchiveList\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_row \u001b[38;5;129;01min\u001b[39;00m results_1st:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_row:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     13\u001b[0m     results_5th \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m url: scappingLotto(url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprize_5th\u001b[39m\u001b[38;5;124m'\u001b[39m), archive\u001b[38;5;241m.\u001b[39marchiveList))\n\u001b[0;32m     14\u001b[0m     results_2digit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m url: scappingLotto(url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprize_2digits\u001b[39m\u001b[38;5;124m'\u001b[39m), archive\u001b[38;5;241m.\u001b[39marchiveList))\n\u001b[1;32m---> 15\u001b[0m     results_3digit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m url: \u001b[43mscappingLotto\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprize_pre_3digit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, archive\u001b[38;5;241m.\u001b[39marchiveList))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m new_row \u001b[38;5;129;01min\u001b[39;00m results_1st:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_row:\n",
      "Cell \u001b[1;32mIn[22], line 53\u001b[0m, in \u001b[0;36mscappingLotto\u001b[1;34m(url, prize_type)\u001b[0m\n\u001b[0;32m     51\u001b[0m                 row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprize_pre_3digit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(num\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     52\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mเลขท้าย\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col\u001b[38;5;241m.\u001b[39mtext:\n\u001b[1;32m---> 53\u001b[0m                 \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprize_sub_3digits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mappend(num\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Adjust prize_pre_3digit and prize_sub_3digits if necessary\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprize_pre_3digit\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprize_sub_3digits\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'prize_sub_3digits'"
     ]
    }
   ],
   "source": [
    "# Main Loop for Scraping Data\n",
    "\n",
    "# Define the main loop that iterates through the archive pages and scrapes data for each prize category\n",
    "while True:\n",
    "    archive = getArchivePage(archive_url)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results_1st = list(executor.map(lambda url: scappingLotto(url, 'prize_1st'), archive.archiveList))\n",
    "        results_nearby_1st = list(executor.map(lambda url: scappingLotto(url, 'nearby_1st'), archive.archiveList))\n",
    "        results_2nd = list(executor.map(lambda url: scappingLotto(url, 'prize_2nd'), archive.archiveList))\n",
    "        results_3rd = list(executor.map(lambda url: scappingLotto(url, 'prize_3rd'), archive.archiveList))\n",
    "        results_4th = list(executor.map(lambda url: scappingLotto(url, 'prize_4th'), archive.archiveList))\n",
    "        results_5th = list(executor.map(lambda url: scappingLotto(url, 'prize_5th'), archive.archiveList))\n",
    "        results_2digit = list(executor.map(lambda url: scappingLotto(url, 'prize_2digits'), archive.archiveList))\n",
    "        results_3digit = list(executor.map(lambda url: scappingLotto(url, 'prize_pre_3digit'), archive.archiveList))\n",
    "\n",
    "    for new_row in results_1st:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_1st = pd.concat([df_1st, newDf], ignore_index=True)\n",
    "            newDf.to_csv('prize_1th.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    for new_row in results_nearby_1st:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_nearby_1st = pd.concat([df_nearby_1st, newDf], ignore_index=True)\n",
    "            newDf.to_csv('nearby_1st.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    for new_row in results_2nd:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_2nd = pd.concat([df_2nd, newDf], ignore_index=True)\n",
    "            newDf.to_csv('prize_2nd.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    for new_row in results_3rd:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_3rd = pd.concat([df_3rd, newDf], ignore_index=True)\n",
    "            newDf.to_csv('prize_3rd.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    for new_row in results_4th:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_4th = pd.concat([df_4th, newDf], ignore_index=True)\n",
    "            newDf.to_csv('prize_4th.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    for new_row in results_5th:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_5th = pd.concat([df_5th, newDf], ignore_index=True)\n",
    "            newDf.to_csv('prize_5th.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    for new_row in results_2digit:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_2digit = pd.concat([df_2digit, newDf], ignore_index=True)\n",
    "            newDf.to_csv('prize_2digit.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    for new_row in results_3digit:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_3digit = pd.concat([df_3digit, newDf], ignore_index=True)\n",
    "            newDf.to_csv('prize_3digit.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    if archive.nextPageUrl == \"\":\n",
    "        df_1st.to_parquet('prize_1th.parquet', index=False)\n",
    "        df_nearby_1st.to_parquet('nearby_1st.parquet', index=False)\n",
    "        df_2nd.to_parquet('prize_2nd.parquet', index=False)\n",
    "        df_3rd.to_parquet('prize_3rd.parquet', index=False)\n",
    "        df_4th.to_parquet('prize_4th.parquet', index=False)\n",
    "        df_5th.to_parquet('prize_5th.parquet', index=False)\n",
    "        df_2digit.to_parquet('prize_2digit.parquet', index=False)\n",
    "        df_3digit.to_parquet('prize_3digit.parquet', index=False)\n",
    "        break\n",
    "    else:\n",
    "        archive_url = archive.nextPageUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 1st Prize Data\n",
    "Scrape the 1st prize data and save it to a CSV and Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape 1st Prize Data\n",
    "\n",
    "# Initialize DataFrame and Variables for 1st Prize\n",
    "columns_1st = ['date', 'prize_1st']\n",
    "df_1st = pd.DataFrame(columns=columns_1st)\n",
    "archive_url = \"https://news.sanook.com/lotto/archive/\"\n",
    "header = True\n",
    "\n",
    "# Remove existing CSV and Parquet files if they exist\n",
    "if os.path.exists('lotto_prize_1th.csv'):\n",
    "    os.remove('lotto_prize_1th.csv')\n",
    "\n",
    "if os.path.exists('lotto_prize_1th.parquet'):\n",
    "    os.remove('lotto_prize_1th.parquet')\n",
    "\n",
    "# Main Loop for Scraping 1st Prize Data\n",
    "while True:\n",
    "    archive = getArchivePage(archive_url)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results_1st = list(executor.map(lambda url: scappingLotto(url, 'prize_1st'), archive.archiveList))\n",
    "\n",
    "    for new_row in results_1st:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_1st = pd.concat([df_1st, newDf], ignore_index=True)\n",
    "            newDf.to_csv('lotto_prize_1th.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    if archive.nextPageUrl == \"\":\n",
    "        df_1st.to_parquet('lotto_prize_1th.parquet', index=False)\n",
    "        break\n",
    "    else:\n",
    "        archive_url = archive.nextPageUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Nearby 1st Prize Data\n",
    "Scrape the nearby 1st prize data and save it to a CSV and Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Nearby 1st Prize Data\n",
    "\n",
    "# Initialize DataFrame and Variables for Nearby 1st Prize\n",
    "columns_nearby_1st = ['date', 'nearby_1st']\n",
    "df_nearby_1st = pd.DataFrame(columns=columns_nearby_1st)\n",
    "archive_url = \"https://news.sanook.com/lotto/archive/\"\n",
    "header = True\n",
    "\n",
    "# Remove existing CSV and Parquet files if they exist\n",
    "if os.path.exists('lotto_nearby_1st.csv'):\n",
    "    os.remove('lotto_nearby_1st.csv')\n",
    "\n",
    "if os.path.exists('lotto_nearby_1st.parquet'):\n",
    "    os.remove('lotto_nearby_1st.parquet')\n",
    "\n",
    "# Main Loop for Scraping Nearby 1st Prize Data\n",
    "while True:\n",
    "    archive = getArchivePage(archive_url)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results_nearby_1st = list(executor.map(lambda url: scappingLotto(url, 'nearby_1st'), archive.archiveList))\n",
    "\n",
    "    for new_row in results_nearby_1st:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_nearby_1st = pd.concat([df_nearby_1st, newDf], ignore_index=True)\n",
    "            newDf.to_csv('lotto_nearby_1st.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    if archive.nextPageUrl == \"\":\n",
    "        df_nearby_1st.to_parquet('lotto_nearby_1st.parquet', index=False)\n",
    "        break\n",
    "    else:\n",
    "        archive_url = archive.nextPageUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 2nd Prize Data\n",
    "Scrape the 2nd prize data and save it to a CSV and Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape 2nd Prize Data\n",
    "\n",
    "# Initialize DataFrame and Variables for 2nd Prize\n",
    "columns_2nd = ['date', 'prize_2nd']\n",
    "df_2nd = pd.DataFrame(columns=columns_2nd)\n",
    "archive_url = \"https://news.sanook.com/lotto/archive/\"\n",
    "header = True\n",
    "\n",
    "# Remove existing CSV and Parquet files if they exist\n",
    "if os.path.exists('lotto_prize_2nd.csv'):\n",
    "    os.remove('lotto_prize_2nd.csv')\n",
    "\n",
    "if os.path.exists('lotto_prize_2nd.parquet'):\n",
    "    os.remove('lotto_prize_2nd.parquet')\n",
    "\n",
    "# Main Loop for Scraping 2nd Prize Data\n",
    "while True:\n",
    "    archive = getArchivePage(archive_url)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results_2nd = list(executor.map(lambda url: scappingLotto(url, 'prize_2nd'), archive.archiveList))\n",
    "\n",
    "    for new_row in results_2nd:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_2nd = pd.concat([df_2nd, newDf], ignore_index=True)\n",
    "            newDf.to_csv('lotto_prize_2nd.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    if archive.nextPageUrl == \"\":\n",
    "        df_2nd.to_parquet('lotto_prize_2nd.parquet', index=False)\n",
    "        break\n",
    "    else:\n",
    "        archive_url = archive.nextPageUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 3rd Prize Data\n",
    "Scrape the 3rd prize data and save it to a CSV and Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape 3rd Prize Data\n",
    "\n",
    "# Initialize DataFrame and Variables for 3rd Prize\n",
    "columns_3rd = ['date', 'prize_3rd']\n",
    "df_3rd = pd.DataFrame(columns=columns_3rd)\n",
    "archive_url = \"https://news.sanook.com/lotto/archive/\"\n",
    "header = True\n",
    "\n",
    "# Remove existing CSV and Parquet files if they exist\n",
    "if os.path.exists('lotto_prize_3rd.csv'):\n",
    "    os.remove('lotto_prize_3rd.csv')\n",
    "\n",
    "if os.path.exists('lotto_prize_3rd.parquet'):\n",
    "    os.remove('lotto_prize_3rd.parquet')\n",
    "\n",
    "# Main Loop for Scraping 3rd Prize Data\n",
    "while True:\n",
    "    archive = getArchivePage(archive_url)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results_3rd = list(executor.map(lambda url: scappingLotto(url, 'prize_3rd'), archive.archiveList))\n",
    "\n",
    "    for new_row in results_3rd:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_3rd = pd.concat([df_3rd, newDf], ignore_index=True)\n",
    "            newDf.to_csv('lotto_prize_3rd.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    if archive.nextPageUrl == \"\":\n",
    "        df_3rd.to_parquet('lotto_prize_3rd.parquet', index=False)\n",
    "        break\n",
    "    else:\n",
    "        archive_url = archive.nextPageUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 4th Prize Data\n",
    "Scrape the 4th prize data and save it to a CSV and Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape 4th Prize Data\n",
    "\n",
    "# Initialize DataFrame and Variables for 4th Prize\n",
    "columns_4th = ['date', 'prize_4th']\n",
    "df_4th = pd.DataFrame(columns=columns_4th)\n",
    "archive_url = \"https://news.sanook.com/lotto/archive/\"\n",
    "header = True\n",
    "\n",
    "# Remove existing CSV and Parquet files if they exist\n",
    "if os.path.exists('lotto_prize_4th.csv'):\n",
    "    os.remove('lotto_prize_4th.csv')\n",
    "\n",
    "if os.path.exists('lotto_prize_4th.parquet'):\n",
    "    os.remove('lotto_prize_4th.parquet')\n",
    "\n",
    "# Main Loop for Scraping 4th Prize Data\n",
    "while True:\n",
    "    archive = getArchivePage(archive_url)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results_4th = list(executor.map(lambda url: scappingLotto(url, 'prize_4th'), archive.archiveList))\n",
    "\n",
    "    for new_row in results_4th:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_4th = pd.concat([df_4th, newDf], ignore_index=True)\n",
    "            newDf.to_csv('lotto_prize_4th.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    if archive.nextPageUrl == \"\":\n",
    "        df_4th.to_parquet('lotto_prize_4th.parquet', index=False)\n",
    "        break\n",
    "    else:\n",
    "        archive_url = archive.nextPageUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 5th Prize Data\n",
    "Scrape the 5th prize data and save it to a CSV and Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape 5th Prize Data\n",
    "\n",
    "# Initialize DataFrame and Variables for 5th Prize\n",
    "columns_5th = ['date', 'prize_5th']\n",
    "df_5th = pd.DataFrame(columns=columns_5th)\n",
    "archive_url = \"https://news.sanook.com/lotto/archive/\"\n",
    "header = True\n",
    "\n",
    "# Remove existing CSV and Parquet files if they exist\n",
    "if os.path.exists('lotto_prize_5th.csv'):\n",
    "    os.remove('lotto_prize_5th.csv')\n",
    "\n",
    "if os.path.exists('lotto_prize_5th.parquet'):\n",
    "    os.remove('lotto_prize_5th.parquet')\n",
    "\n",
    "# Main Loop for Scraping 5th Prize Data\n",
    "while True:\n",
    "    archive = getArchivePage(archive_url)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results_5th = list(executor.map(lambda url: scappingLotto(url, 'prize_5th'), archive.archiveList))\n",
    "\n",
    "    for new_row in results_5th:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_5th = pd.concat([df_5th, newDf], ignore_index=True)\n",
    "            newDf.to_csv('lotto_prize_5th.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    if archive.nextPageUrl == \"\":\n",
    "        df_5th.to_parquet('lotto_prize_5th.parquet', index=False)\n",
    "        break\n",
    "    else:\n",
    "        archive_url = archive.nextPageUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 3-Digit Prize Data\n",
    "Scrape the 3-digit prize data and save it to a CSV and Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape 3-Digit Prize Data\n",
    "\n",
    "# Initialize DataFrame and Variables for 3-Digit Prize\n",
    "columns_3digit = ['date', 'prize_pre_3digit', 'prize_sub_3digits']\n",
    "df_3digit = pd.DataFrame(columns=columns_3digit)\n",
    "archive_url = \"https://news.sanook.com/lotto/archive/\"\n",
    "header = True\n",
    "\n",
    "# Remove existing CSV and Parquet files if they exist\n",
    "if os.path.exists('lotto_prize_3digit.csv'):\n",
    "    os.remove('lotto_prize_3digit.csv')\n",
    "\n",
    "if os.path.exists('lotto_prize_3digit.parquet'):\n",
    "    os.remove('lotto_prize_3digit.parquet')\n",
    "\n",
    "# Main Loop for Scraping 3-Digit Prize Data\n",
    "while True:\n",
    "    archive = getArchivePage(archive_url)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results_3digit = list(executor.map(lambda url: scappingLotto(url, 'prize_pre_3digit'), archive.archiveList))\n",
    "\n",
    "    for new_row in results_3digit:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_3digit = pd.concat([df_3digit, newDf], ignore_index=True)\n",
    "            newDf.to_csv('lotto_prize_3digit.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    if archive.nextPageUrl == \"\":\n",
    "        df_3digit.to_parquet('lotto_prize_3digit.parquet', index=False)\n",
    "        break\n",
    "    else:\n",
    "        archive_url = archive.nextPageUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape 2-Digit Prize Data\n",
    "Scrape the 2-digit prize data and save it to a CSV and Parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape 2-Digit Prize Data\n",
    "\n",
    "# Initialize DataFrame and Variables for 2-Digit Prize\n",
    "columns_2digit = ['date', 'prize_2digits']\n",
    "df_2digit = pd.DataFrame(columns=columns_2digit)\n",
    "archive_url = \"https://news.sanook.com/lotto/archive/\"\n",
    "header = True\n",
    "\n",
    "# Remove existing CSV and Parquet files if they exist\n",
    "if os.path.exists('lotto_prize_2digit.csv'):\n",
    "    os.remove('lotto_prize_2digit.csv')\n",
    "\n",
    "if os.path.exists('lotto_prize_2digit.parquet'):\n",
    "    os.remove('lotto_prize_2digit.parquet')\n",
    "\n",
    "# Main Loop for Scraping 2-Digit Prize Data\n",
    "while True:\n",
    "    archive = getArchivePage(archive_url)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results_2digit = list(executor.map(lambda url: scappingLotto(url, 'prize_2digits'), archive.archiveList))\n",
    "\n",
    "    for new_row in results_2digit:\n",
    "        if new_row:\n",
    "            newDf = pd.DataFrame([new_row])\n",
    "            df_2digit = pd.concat([df_2digit, newDf], ignore_index=True)\n",
    "            newDf.to_csv('lotto_prize_2digit.csv', mode='a', index=False, header=header)\n",
    "            header = False\n",
    "\n",
    "    if archive.nextPageUrl == \"\":\n",
    "        df_2digit.to_parquet('lotto_prize_2digit.parquet', index=False)\n",
    "        break\n",
    "    else:\n",
    "        archive_url = archive.nextPageUrl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
